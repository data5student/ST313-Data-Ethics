{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "384dbc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Main notebook text */\n",
       "body, div, p, span, li, ul, ol, table, th, td {\n",
       "    font-family: \"Times New Roman\", Times, serif !important;\n",
       "    font-size: 12pt;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       "/* Headings */\n",
       "h1, h2, h3, h4, h5, h6 {font-family: \"Times New Roman\", Times, serif !important;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "/* Main notebook text */\n",
    "body, div, p, span, li, ul, ol, table, th, td {\n",
    "    font-family: \"Times New Roman\", Times, serif !important;\n",
    "    font-size: 12pt;\n",
    "    line-height: 1.5;\n",
    "}\n",
    "\n",
    "/* Headings */\n",
    "h1, h2, h3, h4, h5, h6 {font-family: \"Times New Roman\", Times, serif !important;\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2469e",
   "metadata": {},
   "source": [
    "# DATA\n",
    "### In this file, we've included the data cleaning and merging parts so that the main report remains focused. We've submitted this so that anyone who wishes to replicate our report can do so with clarity. In every part of our process, we intent to be as transparent as possible. The output of this report is a final csv file we use for our analysis as well as a comparitive table with the original report.\n",
    "\n",
    "## Table of Contents TO BE FIXED\n",
    "1) [Data Introduction](#intro)\n",
    "    <br>**1.1** Dataset\n",
    "    <br>**1.2** Variables\n",
    "2) [Data Loading](#loading)\n",
    "    <br>**2.1** Kaggle\n",
    "    <br>**2.2** NHANES XPT\n",
    "3) [Data Merging](#merging)\n",
    "4) [Data Filtering](#filter)\n",
    "5) [Replication Conclusion](#conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0cd7a",
   "metadata": {},
   "source": [
    "## 1. Data Introduction <a name=\"intro\"></a>\n",
    "\n",
    "### Dataset\n",
    "In this case, we are using NHANES data. Specifically, a compiled version on Kaggle: https://www.kaggle.com/datasets/cdc/national-health-and-nutrition-examination-survey as it is convenient to access this data. We also pull some necessary data from xpt files on NHANES https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx so that we have a complete table. \n",
    "\n",
    "\n",
    "### Variables We Need\n",
    "We are emulating our chosen report <a href = \"https://nutritionj.biomedcentral.com/articles/10.1186/s12937-025-01173-x#Sec2\">“Exploring the impact of coffee consumption and caffeine intake on cognitive performance in older adults: a comprehensive analysis using NHANES data and gene correlation analysis” </a>. as close as possible so we replicate that variables they use. The report is not very clear on the exact variables it uses as the NHANES has many different variables measuring the same thing. In parts of the report, it lists some covariates and indicates there are more used in the analysis without specifying which ones. Because of these, we cannot be certain that our variables are an exact match, but we try to get as close as possible by looking at the definitions of different variables.\n",
    "\n",
    "To make our process as reproducible as it can be, we've included a table which explicitly documents all the variables that we've used in our report as well the specific datasets they're from. As these variables belong to different datasets, we use <b> \"SEQN\" </b> as the identifier variable to merge on which is the ID number and belongs in every dataset. \n",
    "\n",
    "\n",
    "| Definition                  | NHANES Variable | Dataset                       | Description                              |\n",
    "| ------------------------ | --------------- | ----------------------------- | ---------------------------------------- |\n",
    "| Caffeine intake (mg/day) | `DRXTCAFF`      | Dietary (Kaggle NHANES)       | Total daily caffeine intake (mg/day)     |\n",
    "| CERAD score              | `CFDCSR`        | Questionnaire (NHANES XPT)    | CERAD delayed recall score               |\n",
    "| DSST score               | `CFDDS`         | Questionnaire (NHANES XPT)    | Digit Symbol Substitution Test score     |\n",
    "| Animal Fluency score     | `CFDAST`        | Questionnaire (NHANES XPT)    | Animal Fluency Test score                |\n",
    "| Age (years)              | `RIDAGEYR`      | Demographics (Kaggle NHANES)  | Age at interview                         |\n",
    "| Sex                      | `RIAGENDR`      | Demographics (Kaggle NHANES)  | 1 = male, 2 = female                     |\n",
    "| Race/ethnicity           | `RIDRETH1`      | Demographics (Kaggle NHANES)  | NHANES race/ethnicity categories         |\n",
    "| Marital status           | `DMDMARTL`      | Demographics (Kaggle NHANES)  | Marital status                           |\n",
    "| Body Mass Index          | `BMXBMI`        | Response (Kaggle NHANES)   | Body mass index (kg/m²)                  |\n",
    "| Smoking status           | `SMQ020`        | Questionnaire (NHANES XPT)    | Ever smoked at least 100 cigarettes      |\n",
    "| Alcohol consumption      | `ALQ101`        | Questionnaire (Kaggle NHANES) | Had ≥12 alcoholic drinks in any one year |\n",
    "| Diabetes                 | `DIQ010`        | Questionnaire (Kaggle NHANES) | Doctor-diagnosed diabetes                |\n",
    "| Stroke                   | `MCQ160F`       | Questionnaire (Kaggle NHANES) | Doctor-diagnosed stroke                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82352462",
   "metadata": {},
   "source": [
    "## 2. Data Loading <a name=\"loading\"></a>\n",
    "\n",
    "### Kaggle\n",
    "This is done through importing the library <b> kagglehub </b> and getting a path to the data. Then I download the specific datasets I need from Kaggle, collapse every table into one row for each person for those data sets, keeping the non-empty rows for the variables I will need from each dataset for some variables, using the mean for others, as what's done in the report for <b> DRXTCAFF </b>.\n",
    "\n",
    "\n",
    "### NHANES XPT\n",
    "For the NHANES XPT files, I'll need to import <b> urllib.request </b> so I can access the files straight through their relevant urls. After getting the local file paths, I combine the years (2011-2014) that I need for the report. I do this for the outcome variables, <b> CFDCSR, CFDDS, CFDAST </b> and the smoking variable <b> SMQ020 </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407bb115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: /Users/minaheelkhan/.cache/kagglehub/datasets/nguyenvy/nhanes-19882018/versions/10\n"
     ]
    }
   ],
   "source": [
    "# getting the Kaggle data\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"nguyenvy/nhanes-19882018\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9baecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/m67jcr3d74gdqb7sq9_szhmr0000gn/T/ipykernel_28485/2103738596.py:7: DtypeWarning: Columns (827,831,836,837,841,846,951,952,984,985,986,999,1000,1001) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  resp = pd.read_csv(path + \"/response_clean.csv\")\n"
     ]
    }
   ],
   "source": [
    "# loading individual datasets\n",
    "import pandas as pd\n",
    "\n",
    "demo = pd.read_csv(path + \"/demographics_clean.csv\")\n",
    "diet = pd.read_csv(path + \"/dietary_clean.csv\")\n",
    "quest = pd.read_csv(path + \"/questionnaire_clean.csv\") \n",
    "resp = pd.read_csv(path + \"/response_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4307f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsing every tbale to one row per person for the chosen variables\n",
    "\n",
    "demo_1 = (\n",
    "    demo[[\"SEQN\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDMARTL\", \"SDDSRVYR\"]]\n",
    "    .sort_values(\"SEQN\")\n",
    "    .groupby(\"SEQN\", as_index=False)\n",
    "    .agg(lambda s: s.dropna().iloc[0] if s.notna().any() else pd.NA)\n",
    ")\n",
    "\n",
    "diet_1 = (\n",
    "    diet[[\"SEQN\", \"DRXTCAFF\"]]\n",
    "    .groupby(\"SEQN\", as_index=False)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "quest_1 = (\n",
    "    quest[[\"SEQN\", \"ALQ101\", \"DIQ010\", \"MCQ160F\"]]\n",
    "    .sort_values(\"SEQN\")\n",
    "    .groupby(\"SEQN\", as_index=False)\n",
    "    .agg(lambda s: s.dropna().iloc[0] if s.notna().any() else pd.NA)\n",
    ")\n",
    "\n",
    "resp_1 = (\n",
    "    resp[[\"SEQN\", \"BMXBMI\"]]\n",
    "    .groupby(\"SEQN\", as_index=False)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ffed55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFQ shape: (3472, 4)\n",
      "SMQ shape: (13958, 2)\n",
      "      SEQN  CFDAST  CFDDS  CFDCSR\n",
      "0  62174.0    18.0   33.0     5.0\n",
      "1  62178.0    12.0   38.0     3.0\n",
      "2  62191.0    17.0   26.0     5.0\n",
      "3  62209.0    15.0    NaN     3.0\n",
      "4  62215.0    15.0   47.0     7.0\n",
      "      SEQN  SMQ020\n",
      "0  62161.0     2.0\n",
      "1  62163.0     NaN\n",
      "2  62164.0     2.0\n",
      "3  62165.0     NaN\n",
      "4  62169.0     2.0\n"
     ]
    }
   ],
   "source": [
    "# Getting the XPT data\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# making a folder to store the files\n",
    "os.makedirs(\"nhanes_xpt\", exist_ok=True)\n",
    "\n",
    "# links for cognitifive functions and smoking files from 2011-2014\n",
    "cfq_g_url = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/CFQ_G.xpt\"\n",
    "cfq_h_url = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/CFQ_H.xpt\"\n",
    "smq_g_url = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/SMQ_G.xpt\"\n",
    "smq_h_url = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/SMQ_H.xpt\"\n",
    "\n",
    "# the file paths\n",
    "cfq_g_path = \"nhanes_xpt/CFQ_G.xpt\"\n",
    "cfq_h_path = \"nhanes_xpt/CFQ_H.xpt\"\n",
    "smq_g_path = \"nhanes_xpt/SMQ_G.xpt\"\n",
    "smq_h_path = \"nhanes_xpt/SMQ_H.xpt\"\n",
    "\n",
    "\n",
    "# downloading the files\n",
    "urllib.request.urlretrieve(cfq_g_url, cfq_g_path)\n",
    "urllib.request.urlretrieve(cfq_h_url, cfq_h_path)\n",
    "urllib.request.urlretrieve(smq_g_url, smq_g_path)\n",
    "urllib.request.urlretrieve(smq_g_url, smq_g_path)\n",
    "\n",
    "# reading the files\n",
    "cfq_2011 = pd.read_sas(cfq_g_path, format=\"xport\")\n",
    "cfq_2013 = pd.read_sas(cfq_h_path, format=\"xport\")\n",
    "smq_2011 = pd.read_sas(smq_g_path, format=\"xport\")\n",
    "smq_2013 = pd.read_sas(smq_h_path, format=\"xport\")\n",
    "\n",
    "# combining 2011-2012 with the 2013-2014 files\n",
    "cfq = pd.concat([cfq_2011, cfq_2013], ignore_index=True)\n",
    "smq = pd.concat([smq_2011, smq_2013], ignore_index=True)\n",
    "\n",
    "\n",
    "# filtering to our variables\n",
    "cfq = cfq[[\"SEQN\", \"CFDAST\", \"CFDDS\", \"CFDCSR\"]]\n",
    "smq = smq[[\"SEQN\", \"SMQ020\"]]\n",
    "\n",
    "# checking to make sure importation was done correctly\n",
    "print(\"CFQ shape:\", cfq.shape)\n",
    "print(\"SMQ shape:\", smq.shape)\n",
    "print(cfq.head())\n",
    "print(smq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b272985",
   "metadata": {},
   "source": [
    "## 3. Data Merging <a name=\"merging\"></a>\n",
    "This part is simply just putting all of the cleaned datasets together, using left merge on <b> SEQN </b> to put the kaggle and xpt data in one dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db42bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged df shape: (101316, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>DRXTCAFF</th>\n",
       "      <th>CFDCSR</th>\n",
       "      <th>CFDDS</th>\n",
       "      <th>CFDAST</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>DMDMARTL</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>ALQ101</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>MCQ160F</th>\n",
       "      <th>SMQ020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.403969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14.900</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>438.873869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>24.900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>64.767744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.565</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>147.898003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.400</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25.187899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN    DRXTCAFF  CFDCSR  CFDDS  CFDAST  RIDAGEYR  RIAGENDR  RIDRETH1  \\\n",
       "0     1    2.403969     NaN    NaN     NaN         2         2         4   \n",
       "1     2  438.873869     NaN    NaN     NaN        77         1         3   \n",
       "2     3   64.767744     NaN    NaN     NaN        10         2         3   \n",
       "3     4  147.898003     NaN    NaN     NaN         1         1         4   \n",
       "4     5   25.187899     NaN    NaN     NaN        49         1         3   \n",
       "\n",
       "  DMDMARTL  BMXBMI ALQ101 DIQ010 MCQ160F  SMQ020  \n",
       "0     <NA>  14.900   <NA>    2.0    <NA>     NaN  \n",
       "1     <NA>  24.900    1.0    2.0     2.0     NaN  \n",
       "2      5.0  21.565   <NA>    2.0     2.0     NaN  \n",
       "3      1.0  23.400   <NA>    2.0     2.0     NaN  \n",
       "4      1.0  29.100    1.0    2.0     2.0     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    demo_1[[\"SEQN\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDMARTL\", \"SDDSRVYR\"]]\n",
    "    .merge(diet_1[[\"SEQN\", \"DRXTCAFF\"]], on=\"SEQN\", how=\"left\")\n",
    "    .merge(quest_1[[\"SEQN\", \"ALQ101\", \"DIQ010\", \"MCQ160F\"]], on=\"SEQN\", how=\"left\")\n",
    "    .merge(resp_1[[\"SEQN\", \"BMXBMI\"]], on=\"SEQN\", how=\"left\")\n",
    "    .merge(cfq, on=\"SEQN\", how=\"left\")\n",
    "    .merge(smq, on=\"SEQN\", how = \"left\")\n",
    ")\n",
    "\n",
    "print(\"Merged df shape:\", df.shape)\n",
    "df[[\"SEQN\",\"DRXTCAFF\",\"CFDCSR\",\"CFDDS\",\"CFDAST\",\"RIDAGEYR\",\"RIAGENDR\",\"RIDRETH1\",\"DMDMARTL\",\"BMXBMI\",\"ALQ101\",\"DIQ010\",\"MCQ160F\",\"SMQ020\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fa69e",
   "metadata": {},
   "source": [
    "## 4. Data Filtering <a name=\"filter\"></a>\n",
    "\n",
    "We'll use the same filtering that is done in the paper we're replicating. First it lists the number of participants from 2011-2014 (N = 19931), and then excludes participants with incomplete or unreliable values of cognitive function measures which is anyone under 60 as well (N = 2934), and then excluded participants with missing information for the covariates (N = 2441), and then participants with missing information on caffeine consumption (N = 2254). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc27b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHANES 2011–2014 participants: 20146\n"
     ]
    }
   ],
   "source": [
    "# filtering where participants are from 2011/12 to 2013/14 which corresponds to 8 and 9. \n",
    "df0 = df[df[\"SDDSRVYR\"].isin([8, 9])].copy()\n",
    "print(\"NHANES 2011–2014 participants:\", df0[\"SEQN\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0fc30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Cognitive Function Measure: 1680\n"
     ]
    }
   ],
   "source": [
    "# where they have the cognitive function variables and age >= 60\n",
    "cog_vars = [\"CFDCSR\", \"CFDDS\", \"CFDAST\"]\n",
    "df1 = df0[(df0[\"RIDAGEYR\"] >= 60) & (df0[cog_vars].notna().any(axis=1))].copy()\n",
    "\n",
    "print(\"With Cognitive Function Measure:\", df1[\"SEQN\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a3c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding Missing Covariates: 1602\n"
     ]
    }
   ],
   "source": [
    "# with missing covars\n",
    "covars = [\"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDMARTL\", \"BMXBMI\", \"SMQ020\", \"ALQ101\", \"DIQ010\", \"MCQ160F\"]\n",
    "df2 = df1.dropna(subset=covars).copy()\n",
    "\n",
    "print(\"Excluding Missing Covariates:\", df2[\"SEQN\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaeb428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding Missing Caffiene Consumption: 1482\n"
     ]
    }
   ],
   "source": [
    "# with missing caffiene consumption info\n",
    "df3 = df2.dropna(subset=[\"DRXTCAFF\"]).copy()\n",
    "print(\"Excluding Missing Caffiene Consumption:\", df3[\"SEQN\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1faa910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1a: The Original Report's Filtered Data:  \n",
      "                                                Stage      N\n",
      "0                      NHANES 2011–2014 participants  19931\n",
      "1  Aged ≥60 years with ≥1 cognitive function measure   2934\n",
      "2                        Excluded missing covariates   2441\n",
      "3                   Excluded missing caffeine intake   2254\n",
      "4                              Final analytic sample   2254\n",
      "\n",
      " Table 1b: Our Filtered Data \n",
      "                                                Stage      N\n",
      "0                      NHANES 2011–2014 participants  20146\n",
      "1  Aged ≥60 years with ≥1 cognitive function measure   1680\n",
      "2                        Excluded missing covariates   1602\n",
      "3                   Excluded missing caffeine intake   1482\n",
      "4                              Final analytic sample   1482\n"
     ]
    }
   ],
   "source": [
    "# creating a table to compare with the papers filtering results\n",
    "\n",
    "df_final = df3.copy()\n",
    "\n",
    "table_1b = pd.DataFrame({\n",
    "    \"Stage\": [ \"NHANES 2011–2014 participants\",\n",
    "        \"Aged ≥60 years with ≥1 cognitive function measure\",\n",
    "        \"Excluded missing covariates\",\n",
    "        \"Excluded missing caffeine intake\",\n",
    "        \"Final analytic sample\"],\n",
    "    \"N\": [df0[\"SEQN\"].nunique(),\n",
    "        df1[\"SEQN\"].nunique(),\n",
    "        df2[\"SEQN\"].nunique(),\n",
    "        df3[\"SEQN\"].nunique(),\n",
    "        df_final[\"SEQN\"].nunique()]})\n",
    "\n",
    "\n",
    "table_1a = pd.DataFrame({\n",
    "    \"Stage\": [ \"NHANES 2011–2014 participants\",\n",
    "        \"Aged ≥60 years with ≥1 cognitive function measure\",\n",
    "        \"Excluded missing covariates\",\n",
    "        \"Excluded missing caffeine intake\",\n",
    "        \"Final analytic sample\"],\n",
    "    \"N\": [\"19931\", \"2934\", \"2441\", \"2254\", \"2254\"]\n",
    "})\n",
    "\n",
    "print(\"Table 1a: The Original Report's Filtered Data:  \\n\", table_1a)\n",
    "\n",
    "print(\"\\n Table 1b: Our Filtered Data \\n\", table_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927c9c9",
   "metadata": {},
   "source": [
    "## 5. Replication Conclusion <a name=\"conc\"></a>\n",
    "Comparing our final dataset numbers with the final dataset numbers from the report shows that our data doesn't match up. Especially within the number of participants from the 2011-2014, one wouldn't expect there to be any disrepency, yet we have 215 more participants. Because of this, all further filtering doesn't match up either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da65a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the final dataset as a csv.\n",
    "df_final.to_csv(\"final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad877431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
